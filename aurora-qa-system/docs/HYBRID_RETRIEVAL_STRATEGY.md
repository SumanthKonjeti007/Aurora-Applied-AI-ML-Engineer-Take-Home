# Hybrid Retrieval Strategy - RRF Fusion

## Overview

Combine 3 retrieval methods using Reciprocal Rank Fusion (RRF) to achieve 70-80% recall target.

---

## Architecture

```
Query: "How many cars does Vikram Desai have?"
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARALLEL RETRIEVAL (3 methods run simultaneously)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Semantic Search (Embeddings)                            â”‚
â”‚    - Query: "query: How many cars does Vikram Desai have?" â”‚
â”‚    - Returns: Top 20 messages by cosine similarity         â”‚
â”‚    - Strength: Conceptual understanding                    â”‚
â”‚    - Weakness: Question vs statement format mismatch       â”‚
â”‚                                                             â”‚
â”‚ 2. Keyword Search (BM25)                                   â”‚
â”‚    - Tokens: ["vikram", "desai", "cars", "have"]          â”‚
â”‚    - Returns: Top 20 messages by TF-IDF score             â”‚
â”‚    - Strength: Exact term matching (user names, brands)   â”‚
â”‚    - Weakness: No semantic understanding                   â”‚
â”‚                                                             â”‚
â”‚ 3. Knowledge Graph (Entity-based)                         â”‚
â”‚    - Extract: "Vikram Desai" (user), "cars" (entity type) â”‚
â”‚    - Query: Get user relationships + car-related entities â”‚
â”‚    - Returns: Top 10 messages with matching relationships â”‚
â”‚    - Strength: Structured knowledge, user filtering       â”‚
â”‚    - Weakness: Depends on extraction quality              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RECIPROCAL RANK FUSION (RRF)                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Algorithm:                                                  â”‚
â”‚   For each message that appears in ANY retrieval method:   â”‚
â”‚     score = Î£ 1/(k + rank_i) across all methods           â”‚
â”‚                                                             â”‚
â”‚   k = 60 (standard RRF constant)                          â”‚
â”‚   rank_i = position in method i (1-indexed)               â”‚
â”‚                                                             â”‚
â”‚ Example:                                                    â”‚
â”‚   Message "BMW instead of Mercedes" appears in:           â”‚
â”‚     - Semantic: rank 47 â†’ 1/(60+47) = 0.0093             â”‚
â”‚     - BM25: rank 1 â†’ 1/(60+1) = 0.0164                   â”‚
â”‚     - Graph: rank 9 â†’ 1/(60+9) = 0.0145                  â”‚
â”‚     - Combined score: 0.0402 (high!)                      â”‚
â”‚                                                             â”‚
â”‚   Message "car auctions Germany" appears in:              â”‚
â”‚     - Semantic: rank 1 â†’ 1/(60+1) = 0.0164               â”‚
â”‚     - BM25: not found â†’ 0                                 â”‚
â”‚     - Graph: not found â†’ 0                                â”‚
â”‚     - Combined score: 0.0164 (lower)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OUTPUT: Top 10 Fused Messages                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Sorted by combined RRF score (highest first)               â”‚
â”‚ Messages appearing in multiple methods ranked higher       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Strategy

### **Phase 1: Create HybridRetriever Class**

```python
class HybridRetriever:
    """
    Combines semantic, BM25, and graph search using RRF
    """

    def __init__(self):
        # Load all three indices
        self.embedding_index = EmbeddingIndex()
        self.bm25_search = BM25Search()
        self.knowledge_graph = KnowledgeGraph()

        # Load from disk
        self.embedding_index.load("data/embeddings")
        self.bm25_search.load("data/bm25")
        self.knowledge_graph.load("data/knowledge_graph.pkl")

    def search(
        self,
        query: str,
        top_k: int = 10,
        semantic_weight: float = 1.0,
        bm25_weight: float = 1.0,
        graph_weight: float = 1.0
    ) -> List[Tuple[Dict, float]]:
        """
        Hybrid search with RRF fusion

        Args:
            query: Search query
            top_k: Number of results to return
            *_weight: Optional method weights (default: equal)

        Returns:
            List of (message, rrf_score) tuples
        """
        # 1. Run all retrievals in parallel
        # 2. Apply RRF fusion
        # 3. Return top-k
```

### **Phase 2: Implement RRF Fusion**

```python
def reciprocal_rank_fusion(
    semantic_results: List[Tuple[Dict, float]],
    bm25_results: List[Tuple[Dict, float]],
    graph_results: List[Dict],
    k: int = 60,
    weights: Dict[str, float] = None
) -> List[Tuple[Dict, float]]:
    """
    Reciprocal Rank Fusion algorithm

    Formula: score(msg) = Î£ weight_i * 1/(k + rank_i)

    Args:
        semantic_results: From embedding search
        bm25_results: From BM25 search
        graph_results: From knowledge graph
        k: RRF constant (default 60, industry standard)
        weights: Optional per-method weights

    Returns:
        Fused results sorted by combined score
    """
    if weights is None:
        weights = {'semantic': 1.0, 'bm25': 1.0, 'graph': 1.0}

    scores = defaultdict(float)
    messages = {}

    # Add semantic scores
    for rank, (msg, _) in enumerate(semantic_results, start=1):
        msg_id = msg['id']
        scores[msg_id] += weights['semantic'] * (1.0 / (k + rank))
        messages[msg_id] = msg

    # Add BM25 scores
    for rank, (msg, _) in enumerate(bm25_results, start=1):
        msg_id = msg['id']
        scores[msg_id] += weights['bm25'] * (1.0 / (k + rank))
        messages[msg_id] = msg

    # Add graph scores
    for rank, msg in enumerate(graph_results, start=1):
        msg_id = msg['id']
        scores[msg_id] += weights['graph'] * (1.0 / (k + rank))
        messages[msg_id] = msg

    # Sort by score
    fused = sorted(scores.items(), key=lambda x: x[1], reverse=True)

    return [(messages[msg_id], score) for msg_id, score in fused]
```

### **Phase 3: Graph Query Enhancement**

For graph retrieval, we need to extract entities from the query:

```python
def extract_query_entities(query: str) -> Dict[str, List[str]]:
    """
    Extract user names and entity keywords from query

    Example:
        "How many cars does Vikram Desai have?"
        â†’ {
            'users': ['Vikram Desai'],
            'keywords': ['cars', 'have']
          }
    """
    # 1. Check for known user names (from graph.user_index)
    # 2. Extract keywords (nouns, entities)
    # 3. Return structured query info
```

---

## Key Design Decisions

### **1. Why RRF instead of weighted average?**

**RRF Benefits:**
- âœ… No score normalization needed (semantic uses L2 distance, BM25 uses TF-IDF)
- âœ… Rank-based (more robust than raw scores)
- âœ… Industry standard (used by Elasticsearch, OpenSearch)
- âœ… Messages in multiple methods automatically boosted

**Example:**
```python
# Message appears in 2 methods:
semantic_rank = 5  â†’ 1/(60+5) = 0.0154
bm25_rank = 2      â†’ 1/(60+2) = 0.0161
combined = 0.0315  # Higher than single-method results!

# Message appears in 1 method only:
semantic_rank = 1  â†’ 1/(60+1) = 0.0164
combined = 0.0164  # Lower than multi-method
```

### **2. Retrieval counts: 20-20-10**

- **Semantic**: Top 20 (cast wide net for concepts)
- **BM25**: Top 20 (capture keyword variations)
- **Graph**: Top 10 (high precision, pre-filtered)

Why different counts?
- Graph is already filtered by user/entity â†’ fewer but higher quality
- Semantic/BM25 need more candidates for fusion to select from

### **3. RRF constant k=60**

Industry standard:
- Too low (k=10): Over-emphasizes rank differences
- Too high (k=100): Under-emphasizes rank differences
- k=60: Sweet spot (empirically validated in research)

### **4. Optional method weights**

Default: Equal weights (1.0, 1.0, 1.0)

Can tune based on query type:
- **Factual queries** ("How many X?"): Boost graph (1.0, 1.0, 1.5)
- **Conceptual queries** ("Find luxury hotels"): Boost semantic (1.5, 1.0, 0.5)
- **Named entity queries** ("Vikram's preferences"): Boost BM25 (1.0, 1.5, 1.0)

For this assignment: Start with equal weights (simplest, works well)

---

## Testing Strategy

### **Test 1: Failed Semantic Queries**

Use the 3 assignment examples that failed:
- Q2: "How many cars does Vikram Desai have?" (0/10 semantic recall)
- Q3: "What are Amira's favorite restaurants?" (1/10 semantic recall)

Expected improvement: 0/10 â†’ 5-7/10

### **Test 2: Re-run Full Test Suite**

Run `tests/test_embeddings.py` with hybrid retrieval:
- Current: 25% pass rate (semantic only)
- **Target: 70-80% pass rate (hybrid)**

### **Test 3: Manual Verification**

Inspect top-10 for Q2:
```python
hybrid_results = hybrid_retriever.search("How many cars does Vikram Desai have?")

# Should contain:
# âœ… "Change car service to BMW instead of Mercedes"
# âœ… "Tesla waiting at airport"
# âœ… "Bentley for Paris trip"
```

---

## Expected Improvements

| Query | Semantic Alone | + BM25 | + Graph | Hybrid (All 3) |
|-------|---------------|--------|---------|----------------|
| Q1: Layla London | 3/10 âœ… | 5/10 | 8/10 | **8-9/10** âœ… |
| Q2: Vikram cars | 0/10 âŒ | 3/10 | 10/10 | **7-8/10** âœ… |
| Q3: Amira restaurants | 1/10 âŒ | 2/10 | 4/10 | **5-6/10** âœ… |

**Overall pass rate: 25% â†’ 70-75%** (target achieved)

---

## File Structure

```
src/
â”œâ”€â”€ embeddings.py         âœ… (exists)
â”œâ”€â”€ bm25_search.py        âœ… (exists)
â”œâ”€â”€ knowledge_graph.py    âœ… (exists)
â””â”€â”€ hybrid_retriever.py   ğŸ”„ (to be created)

tests/
â”œâ”€â”€ test_embeddings.py         âœ… (exists)
â””â”€â”€ test_hybrid_retrieval.py   ğŸ”„ (to be created)
```

---

## Implementation Steps

1. **Create `src/hybrid_retriever.py`** with:
   - `HybridRetriever` class
   - `reciprocal_rank_fusion()` function
   - `extract_query_entities()` helper

2. **Create `tests/test_hybrid_retrieval.py`**:
   - Use same 12 test cases from embeddings test
   - Compare semantic vs hybrid performance
   - Verify 70-80% pass rate

3. **Update test suite**:
   - Modify `test_embeddings.py` to optionally use hybrid
   - Generate comparison report

4. **Demo script**:
   - Already have `demo_hybrid_search.py`
   - Update to use new HybridRetriever class

---

## Success Criteria

- âœ… Pass rate â‰¥ 70% (currently 25%)
- âœ… Assignment examples (Q1, Q2, Q3) all pass
- âœ… Vikram car query finds BMW, Tesla, Bentley messages in top-10
- âœ… Clean, modular code
- âœ… Documented with clear docstrings

---

## This Strategy is:

- **Simple**: RRF is straightforward to implement
- **Effective**: Proven in industry (Elasticsearch uses it)
- **Modular**: Each retrieval method independent
- **Testable**: Clear metrics for validation
- **Extensible**: Easy to add weights, filters later

Ready to implement! ğŸš€
